{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d745954",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-c02b6cf7b2a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m \u001b[0;31m#Digunakan untuk initialize ANN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDense\u001b[0m \u001b[0;31m#Digunakan untuk membuat layers di ANN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9c95c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Downloading keras-2.7.0-py2.py3-none-any.whl (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 970 kB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: keras\n",
      "Successfully installed keras-2.7.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11386a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from tensorflow.keras.models import Sequential #Digunakan untuk initialize ANN\n",
    "from tensorflow.keras.layers import Dense #Digunakan untuk membuat layers di ANN\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "@st.cache(suppress_st_warning=True, allow_output_mutation=True)\n",
    "def loadData():\n",
    "\tdataset = pd.read_csv('heart.csv')\n",
    "\treturn dataset\n",
    "\n",
    "# Basic preprocessing \n",
    "def preprocessing(dataset):\n",
    "    dataset.columns = ['age', 'sex', 'cp', 'trestbps', 'chol',\n",
    "              'fbs', 'restecg', 'thalach', 'exang', \n",
    "              'oldpeak', 'slope', 'ca', 'thal', 'target']\n",
    "    dataset['target'] = dataset.target.map({0: 0, 1: 1, 2: 1, 3: 1, 4: 1})\n",
    "    dataset['thal'] = dataset.thal.fillna(dataset.thal.mean())\n",
    "    dataset['ca'] = dataset.ca.fillna(dataset.ca.mean())\n",
    "\n",
    "    X = dataset.iloc[:, :-1].values\n",
    "    y = dataset.iloc[:, -1].values\n",
    "\n",
    "    # Splitting data menjadi Training set and Test set\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "    return X_train,X_test,y_train,y_test\n",
    "\n",
    "# Training Neural Network for Classification.\n",
    "@st.cache(suppress_st_warning=True, allow_output_mutation=True)\n",
    "def neuralNet(X_train, X_test, y_train, y_test):\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "\n",
    "    #train data\n",
    "    #initializing the ANN\n",
    "    classifier = Sequential()\n",
    "\n",
    "    #input layer\n",
    "    classifier.add(Dense(activation=\"relu\", input_dim=13, units=13, kernel_initializer=\"uniform\"))\n",
    "    \n",
    "    #hidden layer\n",
    "    classifier.add(Dense(activation=\"relu\", units=2, kernel_initializer=\"uniform\"))\n",
    "    \n",
    "    #output layer\n",
    "    classifier.add(Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\"))\n",
    "\n",
    "    #Compiling ANN\n",
    "    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "    #Fitting classifier ke Training set\n",
    "    history = classifier.fit(X_train, y_train, batch_size = 100, epochs = 150)\n",
    "\n",
    "#Scalling data sebelum memasukannya ke Neural Network.\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from sklearn.metrics import classification_report\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    y_pred = (y_pred > 0.5)\n",
    "    score1 = accuracy_score(y_test, y_pred)*100\n",
    "    report = classification_report(y_test, y_pred)\n",
    "\t\n",
    "    return score1, report, classifier\n",
    "\n",
    "def graphic(X_train, X_test, y_train, y_test):\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "\n",
    "    #Training data\n",
    "    #Initializing ANN\n",
    "    classifier = Sequential()\n",
    "\n",
    "    #input layer\n",
    "    classifier.add(Dense(activation=\"relu\", input_dim=13, units=13, kernel_initializer=\"uniform\"))\n",
    "    \n",
    "    #hidden layer\n",
    "    classifier.add(Dense(activation=\"relu\", units=2, kernel_initializer=\"uniform\"))\n",
    "    \n",
    "    #output layer\n",
    "    classifier.add(Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\"))\n",
    "\n",
    "    #Compiling ANN\n",
    "    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "    #Fitting classifier ke Training set\n",
    "    history = classifier.fit(X_train, y_train, batch_size = 100, epochs = 150)\n",
    "\n",
    "    # Grafik History Accuracy\n",
    "    fig = plt.figure(figsize=(10, 5))\n",
    "    plt.plot(range(150), history.history['accuracy'])\n",
    "    st.write(\"History Accuracy : \")\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    st.pyplot(fig)\n",
    "\t\n",
    "# Grafik History Loss\n",
    "    fig = plt.figure(figsize=(10, 5))\n",
    "    plt.plot(range(150), history.history['loss'])\n",
    "    st.write(\"History Loss : \")\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    st.pyplot(fig)\n",
    "    \n",
    "def prediction(name,age,sex,cp,tresthbp,chol,fbs,restecg,thalach,exang,oldpeak,slope,cs,thal):\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    sc = StandardScaler()\n",
    "    data = loadData()\n",
    "    X_train, X_test, y_train, y_test = preprocessing(data)\n",
    "    score1, report, classifier = neuralNet(X_train, X_test, y_train, y_test)\n",
    "    prediksi = classifier.predict(sc.fit_transform(np.array([[age,sex,cp,tresthbp,chol,fbs,restecg,thalach,exang,oldpeak,slope,cs,thal]])))\n",
    "    prediksi_perc = int(prediksi * 100)\n",
    "    if prediksi_perc > 50:\n",
    "        st.write(\"Saudara \",name,\" Memiliki kemungkinan penyakit jantung\")\n",
    "    else :\n",
    "        st.write(\"Saudara \",name,\"Tidak memiliki kemungkinan penyakit jantung\")\n",
    "\t\t\t\n",
    "    \n",
    "\n",
    "def main():\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    sc = StandardScaler()\n",
    "    st.title(\"KLASIFIKASI PENYAKIT JANTUNG\")\n",
    "    st.markdown(\"Aplikasi ini dibuat untuk mangklasifikasikan apakah seseorang memiliki kemungkinan penyakit jantung atau tidak, menggunakan Artificial Neural Network dengan Epochs 150.\")\n",
    "    data = loadData()\n",
    "    X_train, X_test, y_train, y_test = preprocessing(data)\n",
    "    score1, report, classifier = neuralNet(X_train, X_test, y_train, y_test)\n",
    "    st.write(\"Tingkat Keakuratan Model : \",score1)\n",
    "    graphic(X_train, X_test, y_train, y_test)\n",
    "    st.text(\" \\n\")\n",
    "    st.text(\" \\n\")\n",
    "    st.text(\" \\n\")\n",
    "    st.write(\"KLASIFIKASIKAN DATA\")\n",
    "    name = st.text_input(\"Masukkan nama anda : \",'nama')\n",
    "    age = st.number_input(\"Masukkan usia anda\",0,100,0)\n",
    "    pilih_sex = st.radio(\"Pilih jenis kelamin \",options=['Laki-laki','Perempuan'])\n",
    "    sex = 0\n",
    "    if pilih_sex == 'Laki-laki':\n",
    "        sex = 1\n",
    "    else :\n",
    "        sex = 0\n",
    "    display_cp = st.checkbox(\"Apakah anda mengalami sakit di dada ? *centang jika iya\")\n",
    "    cp = 0\n",
    "    if display_cp:\n",
    "        pilih_cp = st.radio(\"Pilih jenis sakit yang anda rasakan : \",options=['Typical Angina','Atypical angina','Non-anginal pain','Asymptotic'])\n",
    "        if pilih_cp == 'Typical Angina':\n",
    "            cp = 1\n",
    "        elif pilih_cp == 'Atypical angina':\n",
    "            cp = 2\n",
    "        elif pilih_cp == 'Non-anginal pain':\n",
    "            cp = 3\n",
    "        else :\n",
    "            cp = 4\n",
    "    tresthbp = st.number_input(\"Masukkan tekanan darah anda (/mmHg) : \",50,400,120)\n",
    "    chol = st.number_input(\"Masukkan kadar kolesterol darah anda (mg/dL) :\",100,400,180)\n",
    "    pilih_fbs = st.checkbox(\"Apakah anda memiliki gula daran lebih dari 120mg/dL ? Centang jika iya\")\n",
    "    fbs = 0\n",
    "    if pilih_fbs:\n",
    "        fbs = 1\n",
    "    pilih_restecg = st.radio(\"Pilih hasil elektrokardiografi anda : \",options=['Normal','ST-T wave abnormality','Left ventricular hyperthroph'])\n",
    "    restecg = 0\n",
    "    if pilih_restecg == 'Normal':\n",
    "        restecg = 1\n",
    "    elif pilih_restecg == 'ST-T wave abnormality':\n",
    "        restecg = 2\n",
    "    else :\n",
    "        restecg = 0\n",
    "    thalach = st.number_input(\"Masukkan tekanan darah tertinggi anda (/mmHg) : \",50,400,120)\n",
    "    pilih_exang = st.checkbox(\"Apakah ketika melakukan aktivitas fisik berat seperti olahraga , dada anda terasa sakit ? Centang jika iya\")\n",
    "    exang = 0\n",
    "    if pilih_exang:\n",
    "        exang = 1 \n",
    "    oldpeak = st.number_input(\"Masukkan nilai ST Depression : \",0,10,1)\n",
    "    pilih_slope = st.radio(\"Masukkan bentuk kurva ST \",options=['Unsloping','Flat','Downsloping'])\n",
    "    slope = 1\n",
    "    if pilih_slope == 'Unsloping':\n",
    "        slope = 2\n",
    "    elif pilih_slope == 'Flat':\n",
    "        slope =1\n",
    "    else:\n",
    "        slope = 0\n",
    "    cs = st.number_input(\"Masukkan pembuluh darah utama diwarnai dengan fluoroskopi\",0,3,1)\n",
    "    pilih_thal = st.radio(\"Kelainan Thalassemia \",options=['Normal','Fixed defect','reversible defect'])\n",
    "    thal = 3\n",
    "    if pilih_thal == 'Normal':\n",
    "        thal = 2\n",
    "    elif pilih_thal == 'Fixed defect':\n",
    "        thal = 1\n",
    "    else :\n",
    "        thal = 3\n",
    "    st.write(name,age,sex,cp,tresthbp,chol,fbs,restecg,thalach,exang,oldpeak,slope,cs,thal)\n",
    "    butt = st.button('Klasifikasikan')\n",
    "    if butt:\n",
    "        prediction(name,age,sex,cp,tresthbp,chol,fbs,restecg,thalach,exang,oldpeak,slope,cs,thal)\n",
    "if __name__ == \"__main__\":\n",
    "\tmain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "131ac0d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.7.0-cp38-cp38-macosx_10_11_x86_64.whl (207.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 207.1 MB 134 kB/s eta 0:00:01██████████████             | 123.2 MB 900 kB/s eta 0:01:34 |██████████████████████████▌     | 171.8 MB 1.4 MB/s eta 0:00:26\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /Users/rafi/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.20.1)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /Users/rafi/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (3.19.1)\n",
      "Collecting absl-py>=0.4.0\n",
      "  Downloading absl_py-1.0.0-py3-none-any.whl (126 kB)\n",
      "\u001b[K     |████████████████████████████████| 126 kB 664 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting libclang>=9.0.1\n",
      "  Downloading libclang-12.0.0-py2.py3-none-macosx_10_9_x86_64.whl (12.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 12.2 MB 1.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.6 in /Users/rafi/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (3.7.4.3)\n",
      "Collecting keras-preprocessing>=1.1.1\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "\u001b[K     |████████████████████████████████| 42 kB 1.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: keras<2.8,>=2.7.0rc0 in /Users/rafi/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (2.7.0)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[K     |████████████████████████████████| 57 kB 2.9 MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting tensorflow-io-gcs-filesystem>=0.21.0\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.23.1-cp38-cp38-macosx_10_14_x86_64.whl (1.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6 MB 2.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorboard~=2.6\n",
      "  Downloading tensorboard-2.7.0-py3-none-any.whl (5.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.8 MB 3.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting termcolor>=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.32.0 in /Users/rafi/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (0.36.2)\n",
      "Collecting tensorflow-estimator<2.8,~=2.7.0rc0\n",
      "  Downloading tensorflow_estimator-2.7.0-py2.py3-none-any.whl (463 kB)\n",
      "\u001b[K     |████████████████████████████████| 463 kB 3.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.43.0-cp38-cp38-macosx_10_10_x86_64.whl (4.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.2 MB 3.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting gast<0.5.0,>=0.2.1\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[K     |████████████████████████████████| 65 kB 4.0 MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/rafi/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/rafi/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/rafi/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (2.10.0)\n",
      "Collecting flatbuffers<3.0,>=1.12\n",
      "  Downloading flatbuffers-2.0-py2.py3-none-any.whl (26 kB)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.3.3-py2.py3-none-any.whl (155 kB)\n",
      "\u001b[K     |████████████████████████████████| 155 kB 4.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2.21.0 in /Users/rafi/opt/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (2.25.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /Users/rafi/opt/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (1.0.1)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\n",
      "\u001b[K     |████████████████████████████████| 781 kB 3.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-macosx_10_9_x86_64.whl (3.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.5 MB 2.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /Users/rafi/opt/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (52.0.0.post20210125)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.6-py3-none-any.whl (97 kB)\n",
      "\u001b[K     |████████████████████████████████| 97 kB 5.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.8-py3-none-any.whl (39 kB)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /Users/rafi/opt/anaconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.2.4)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "\u001b[K     |████████████████████████████████| 155 kB 4.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting importlib-metadata>=4.4\n",
      "  Downloading importlib_metadata-4.9.0-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/rafi/opt/anaconda3/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow) (3.4.1)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "\u001b[K     |████████████████████████████████| 77 kB 3.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /Users/rafi/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/rafi/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/rafi/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/rafi/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.26.4)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.1-py2.py3-none-any.whl (146 kB)\n",
      "\u001b[K     |████████████████████████████████| 146 kB 3.3 MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: termcolor\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4829 sha256=52de820a5c16a6293cfd066fe34cf7da3910003075e4df9eef1df237f3c3d19c\n",
      "  Stored in directory: /Users/rafi/Library/Caches/pip/wheels/a0/16/9c/5473df82468f958445479c59e784896fa24f4a5fc024b0f501\n",
      "Successfully built termcolor\n",
      "Installing collected packages: pyasn1, rsa, pyasn1-modules, oauthlib, requests-oauthlib, importlib-metadata, google-auth, tensorboard-plugin-wit, tensorboard-data-server, markdown, grpcio, google-auth-oauthlib, absl-py, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard, opt-einsum, libclang, keras-preprocessing, google-pasta, gast, flatbuffers, astunparse, tensorflow\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 3.10.0\n",
      "    Uninstalling importlib-metadata-3.10.0:\n",
      "      Successfully uninstalled importlib-metadata-3.10.0\n",
      "Successfully installed absl-py-1.0.0 astunparse-1.6.3 flatbuffers-2.0 gast-0.4.0 google-auth-2.3.3 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.43.0 importlib-metadata-4.9.0 keras-preprocessing-1.1.2 libclang-12.0.0 markdown-3.3.6 oauthlib-3.1.1 opt-einsum-3.3.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.0 rsa-4.8 tensorboard-2.7.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.0 tensorflow-2.7.0 tensorflow-estimator-2.7.0 tensorflow-io-gcs-filesystem-0.23.1 termcolor-1.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa529d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
